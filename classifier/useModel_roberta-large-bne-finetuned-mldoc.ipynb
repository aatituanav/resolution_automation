{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets tensorflow huggingface_hub -q > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ltO5Xb-594N"
   },
   "source": [
    "# roberta-large-bne-finetuned-mldoc\n",
    "\n",
    "El presente colab se utiliza únicamente para inferencias del modelo ya entrenado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gQm2BkWMiUb"
   },
   "source": [
    "# Cargar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b8150f60e046edaacb1318cc8ad0f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from huggingface_hub import from_pretrained_keras\n",
    "from transformers import AutoTokenizer, TFRobertaModel\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "repo_id = \"aatituanav/roberta-base-bne-mldoc-4cat\"\n",
    "\n",
    "# descarga de el repositorio completo\n",
    "local_dir = snapshot_download(repo_id=repo_id)\n",
    "\n",
    "# carga el modelo\n",
    "model = tf.keras.models.load_model(\n",
    "    local_dir,\n",
    "    custom_objects={\"TFRobertaModel\": TFRobertaModel}\n",
    ")\n",
    "\n",
    "# carga el tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWPSMVJOxAxR"
   },
   "source": [
    "# Utilización del Modelo\n",
    "Se clasifican resoluciones de 4 categorias:\n",
    "*   Infraestructura y Recursos\n",
    "*   Nombramientos de Personal\n",
    "*   Aprobaciones de Planes\n",
    "*   Modificaciones Reglamentarias\n",
    "\n",
    "#se utilizan las resoluciones del documento proporcionado para las inferencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir_texto(texto, tokenizer, model, max_length=256):\n",
    "    # Tokenizar el texto de entrada\n",
    "    inputs = tokenizer(\n",
    "        texto,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=True,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "    # Hacer la predicción\n",
    "    logits = model.predict({\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"]\n",
    "    })\n",
    "\n",
    "    # Clase predicha\n",
    "    clase_predicha = tf.argmax(logits, axis=1).numpy()[0]\n",
    "\n",
    "    # Probabilidades de cada clase\n",
    "    probabilidades = tf.nn.softmax(logits, axis=1).numpy()[0]\n",
    "\n",
    "    return clase_predicha, probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "Resultado de la predicción:\n",
      "Texto: Artículo 1.- Aprobación del Cronograma para Elecciones de Representantes\n",
      "Estudiantiles del Instituto Superior Tecnológico Yaruquí.  \n",
      "Clase predicha: 2 - Aprobaciones de Planes\n",
      "Probabilidades:\n",
      "   Clase 0 (Infraestructura y Recursos): 0.1822\n",
      "   Clase 1 (Nombramientos de Personal): 0.1888\n",
      "   Clase 2 (Aprobaciones de Planes): 0.4442\n",
      "   Clase 3 (Modificaciones Reglamentarias): 0.1848\n"
     ]
    }
   ],
   "source": [
    "texto_ejemplo = \"\"\"Artículo 1.- Aprobación del Cronograma para Elecciones de Representantes\n",
    "Estudiantiles del Instituto Superior Tecnológico Yaruquí.  \"\"\"\n",
    "\n",
    "# Predecir\n",
    "clase, probs = predecir_texto(texto_ejemplo, tokenizer, model)\n",
    "\n",
    "clases = {\n",
    "    \"0\": \"Infraestructura y Recursos\",\n",
    "    \"1\": \"Nombramientos de Personal\",\n",
    "    \"2\": \"Aprobaciones de Planes\",\n",
    "    \"3\": \"Modificaciones Reglamentarias\"\n",
    "}\n",
    "\n",
    "print(\"Resultado de la predicción:\")\n",
    "print(f\"Texto: {texto_ejemplo}\")\n",
    "print(f\"Clase predicha: {clase} - {clases[str(clase)]}\")\n",
    "print(f\"Probabilidades:\")\n",
    "for i, prob in enumerate(probs):\n",
    "    print(f\"   Clase {i} ({clases[str(i)]}): {prob:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
